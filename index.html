<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>HumanSAM:ClassifyingHuman-centricForgeryVideos
    inHumanSpatial,Appearance,andMotionAnomaly</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">HumanSAM : Classifying Human-centric Forgery Videos in Human
              Spatial, Appearance, and Motion Anomaly</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://dejian-lc.github.io/" target="_blank">Chang Liu</a><sup>*,1</sup>,</span>
              <span class="author-block">
                <a href="https://yunfan1202.github.io/" target="_blank"> &nbsp;Yunfan Ye</a><sup>*,2</sup>,</span>
              <span class="author-block">
                &nbsp;Fan Zhang<sup>1</sup>,
              </span>
              <span class="author-block">
                &nbsp;Qingyang Zhou<sup>1</sup>,
              </span><span class="author-block">
                &nbsp;Yuchuan Luo<sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="http://individual.utoronto.ca/zcai/" target="_blank"> &nbsp;Zhiping
                  Cai</a><sup>†,1</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup> National University of Defense Technology,
                &nbsp;&nbsp;<sup>2</sup> Hunan University <br>ICCV 2025</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
              <span class="eql-cntrb"><small><br><sup>†</sup>Corresponding Author</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <!-- <span class="link-block">
                  <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span> -->

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/dejian-lc/humansam" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2507.19924" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Teaser video-->
  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          Your video here
          <source src="static/videos/banner_video.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat
          pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus.
        </h2>
      </div>
    </div>
  </section> -->
  <!-- End teaser video -->

  <!-- Teaser image-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="static/images/fig1.jpg" alt="HumanSAM Teaser" style="width: 100%; height: auto;">
        <h2 class="subtitle has-text-centered">
          HumanSAM framework overview showing classification of human-centric forgery videos into three distinct anomaly
          types: spatial, appearance, and motion anomaly.
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser image -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Numerous synthesized videos from generative models, especially human-centric ones that simulate realistic
              human actions, pose significant threats to human information security and authenticity. While progress has
              been made in binary forgery video detection, the lack of fine-grained understanding of forgery types
              raises concerns regarding both reliability and interpretability, which are critical for real-world
              applications. To address this limitation, we propose HumanSAM, a new framework that builds upon the
              fundamental challenges of video generation models. Specifically, HumanSAM aims to classify human-centric
              forgeries into three distinct types of artifacts commonly observed in generated content: spatial,
              appearance, and motion anomaly. To better capture the features of geometry, semantics and spatiotemporal
              consistency, we propose to generate the human forgery representation by fusing two branches of video
              understanding and spatial depth. We also adopt a rank-based confidence enhancement strategy during the
              training process to learn more robust representation by introducing three prior scores. For training and
              evaluation, we construct the first public benchmark, the Human-centric Forgery Video (HFV) dataset, with
              all types of forgeries carefully annotated semi-automatically. In our experiments, HumanSAM yields
              promising results in comparison with state-of-the-art methods, both in binary and multi-class forgery
              classification.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- Method -->
  <section class="hero is-white">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h2 class="title is-3 has-text-centered">Method</h2>
        <img src="static/images/fig2.jpg" alt="HumanSAM Method" style="width: 100%; height: auto;">
        <div class="content has-text-justified" style="margin-top: 20px;">
          <p>
            Our proposed HumanSAM framework consists of three main components: (1) A dual-branch architecture that 
            combines video understanding and spatial depth analysis to capture geometry, semantics, and spatiotemporal 
            consistency features; (2) A rank-based confidence enhancement strategy that leverages three prior scores 
            to learn more robust representations during training; and (3) A multi-class classification head that 
            categorizes human-centric forgeries into spatial, appearance, and motion anomaly types. The framework 
            processes input videos through both RGB and depth modalities, extracting complementary features that are 
            fused to create comprehensive human forgery representations for accurate classification.
          </p>
        </div>
      </div>
    </div>
  </section>
  <!-- End method -->


  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3 has-text-centered">Qualitative Display of Anomaly Images </h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/spatital.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered content has-text-justified">
              <b>Spatital Anomaly : </b>It can be seen that in the first row, two metal knives blur and pass through each other; in the second
              row, a woman's hand blurs as it reaches into the harp; in the third row, a person's hand passes through a
              clay pot under production without leaving any traces. Overall, this violates spatial logic and the normal
              rules of object interaction.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/appearance.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered content has-text-justified">
              <b>Appearance Anomaly : </b>It can be seen that in the first row, the hand on the right suddenly
              changes from an apparently left hand to a right hand. In the second row, the number of fingers on the
              right hand changes from six to five. In the third row, the object held in the hand gradually disappears.
              Generally speaking, the consistency in appearance cannot be maintained.

            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/motion.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered content has-text-justified">
              <b>Motion Anomaly : </b>It can be observed that in the first row, the woman's body maintains a
              forward-leaning tendency, but her head suddenly rotates 180 degrees. In the second row, the girl's right
              hand takes on the shape of a left hand. In the third row, the girl's right hand assumes the posture of a
              left hand, which would be appropriate if the girl's body were rotated around. Generally speaking, the
              motion of the characters does not conform to normal biological motion patterns.
            </h2>
          </div>
          <!-- <div class="item">
            Your image here
            <img src="static/images/carousel4.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Fourth image description.
            </h2>
          </div> -->
        </div>
      </div>
    </div>
  </section>
  <!-- End image carousel -->





  <!-- Video carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Another Carousel</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-video1">
            <video poster="" id="video1" autoplay controls muted loop height="100%">
              <!-- Your video file here -->
              <source src="static/videos/carousel1.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video2">
            <video poster="" id="video2" autoplay controls muted loop height="100%">
              <!-- Your video file here -->
              <source src="static/videos/carousel2.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-video3">
            <video poster="" id="video3" autoplay controls muted loop height="100%">\
              <!-- Your video file here -->
              <source src="static/videos/carousel3.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End video carousel -->






  <!-- Paper poster -->
  <!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
  <!--End paper poster -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{liu2025humansam,
  title={HumanSAM: Classifying Human-centric Forgery Videos in Human Spatial, Appearance, and Motion Anomaly},
  author={Liu, Chang and Ye, Yunfan and Zhang, Fan and Zhou, Qingyang and Luo, Yuchuan and Cai, Zhiping},
  journal={arXiv preprint arXiv:2507.19924},
  year={2025}
}</code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in the
              footer. <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>